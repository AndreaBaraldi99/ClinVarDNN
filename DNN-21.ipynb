{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from warnings import simplefilter\n",
    "set_seed(42)\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clinvar.hg19.chr21.dbnsfp.tsv', sep='\\t')\n",
    "print(df.shape)\n",
    "df = df.apply(lambda x: x.str.split(';') if x.dtype == \"object\" else x)\n",
    "df = df.map(lambda x: x.remove('') if type(x) is list and '' in x else x)\n",
    "\n",
    "l = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].apply(lambda x: len(x) if type(x) is list else list()).equals(df['aapos'].apply(lambda x: len(x) if type(x) is list else list())):\n",
    "        l.append(col)\n",
    "\n",
    "l.append('TSL')\n",
    "df = df.explode(l)\n",
    "df = df.map(lambda x: x[0] if type(x) is list and len(x) == 1 else x)\n",
    "#print(df['Pathway(ConsensusPathDB)'].apply(lambda x: len(x) if type(x) is list else list()))\n",
    "l1 = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].map(lambda x: True if type(x) is list else False).any():\n",
    "        l1.append(col)\n",
    "\n",
    "#print(l1)\n",
    "#MutationTaster_score and MGI_mouse_phenotype\n",
    "#df['MutationTaster_score'] = df['MutationTaster_score'].apply(lambda x: np.mean([float(numeric_string) for numeric_string in x]) if type(x) is list else x)\n",
    "v = sorted(df['MGI_mouse_phenotype'].explode().unique())\n",
    "#for c in v:\n",
    "    #df[c] = df['MGI_mouse_phenotype'].apply(lambda lis: int(c in lis))\n",
    "#df.drop(['MGI_mouse_phenotype', ' '], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df.drop(l1, axis=1, inplace=True)\n",
    "df.to_csv('test.csv', index=False, sep='\\t')\n",
    "#print(len(df['GO_cellular_component'].explode().unique()))\n",
    "#print(sorted(df['Pathway(ConsensusPathDB)'].explode().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('clinvar.hg19.chr21.dbnsfp.tsv', sep='\\t')\n",
    "df.replace(to_replace='.', value=np.nan, inplace=True)\n",
    "#df.replace(regex='^[.;]+$', value=np.nan, inplace=True)\n",
    "df.apply(pd.to_numeric, errors='ignore')\n",
    "df.dropna(axis='rows', how='any', inplace=True, subset=['clinvar_clnsig'])\n",
    "df.dropna(axis='columns', thresh=int(len(df.index)*0.8), inplace=True)\n",
    "df.drop(axis='index', labels=df[df.clinvar_clnsig == 'not_provided'].index, inplace=True)\n",
    "df.drop(axis='index', labels=df[df.clinvar_clnsig == 'protective'].index, inplace=True)\n",
    "df.drop(axis='index', labels=df[df.clinvar_clnsig == 'risk_factor'].index, inplace=True)\n",
    "df.drop(axis='index', labels=df[df.clinvar_clnsig == 'Conflicting_interpretations_of_pathogenicity,_risk_factor'].index, inplace=True)\n",
    "df.drop(axis='index', labels=df[df.clinvar_clnsig == 'Conflicting_interpretations_of_pathogenicity,_other,_risk_factor'].index, inplace=True)\n",
    "df.replace(to_replace='Conflicting_interpretations_of_pathogenicity', value='Uncertain_significance', inplace=True)\n",
    "df.replace(to_replace='Benign/Likely_benign', value='Benign', inplace=True)\n",
    "df.replace(to_replace='Pathogenic/Likely_pathogenic', value='Pathogenic', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter(valid_pct=0.2, seed=42)(range_of(df))\n",
    "df_data = df.drop(columns=['clinvar_clnsig'], inplace=False)\n",
    "num_cols = df_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df_data.select_dtypes(include=[object]).columns.tolist()\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
    "                   cat_names = cat_cols,\n",
    "                   cont_names = num_cols,\n",
    "                   y_names='clinvar_clnsig',\n",
    "                    y_block=CategoryBlock(),\n",
    "                   splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=accuracy, loss_func=FocalLossFlat(gamma=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(20, 1e-3, wd=0.01)\n",
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('clinvar.22.dbnsfp.vcf', sep='\\t')\n",
    "test_df = test_df[df.columns]\n",
    "test_df = test_df.apply(lambda x: x.str.split(';') if x.dtype == \"object\" else x)\n",
    "test_df = test_df.map(lambda x: x.remove('') if type(x) is list and '' in x else x)\n",
    "\n",
    "l = []\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].apply(lambda x: len(x) if type(x) is list else list()).equals(df['aapos'].apply(lambda x: len(x) if type(x) is list else list())):\n",
    "        l.append(col)\n",
    "\n",
    "l.append('TSL')\n",
    "test_df = test_df.explode(l)\n",
    "test_df = test_df.map(lambda x: x[0] if type(x) is list and len(x) == 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_df.replace(to_replace='.', value=np.NaN, inplace=True)\n",
    "#test_df.replace(regex='^[.;]+$', value=np.NaN, inplace=True)\n",
    "test_df.apply(pd.to_numeric, errors='ignore')\n",
    "test_df.dropna(axis='rows', how='any', inplace=True, subset=['clinvar_clnsig'])\n",
    "test_df = test_df[df.columns]\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'not_provided'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'protective'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'risk_factor'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'Conflicting_interpretations_of_pathogenicity,_risk_factor'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'Conflicting_interpretations_of_pathogenicity,_other,_risk_factor'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'drug_response'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'association'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'Affects'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'other'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'drug_response,_risk_factor'].index, inplace=True)\n",
    "test_df.replace(to_replace='Conflicting_interpretations_of_pathogenicity', value='Uncertain_significance', inplace=True)\n",
    "test_df.replace(to_replace='Benign/Likely_benign', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Likely_benign,_other', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Likely_benign,_drug_response,_other', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Benign/Likely_benign,_other', value='Likely_benign', inplace=True)\n",
    "#test_df.replace(to_replace='Benign/Likely_benign,_other,_risk_factor', value='Likely_benign', inplace=True)\n",
    "#test_df.replace(to_replace='Benign/Likely_benign,_risk_factor', value='Likely_benign', inplace=True)\n",
    "#test_df.replace(to_replace='Pathogenic/Likely_pathogenic', value='Likely_pathogenic', inplace=True)\n",
    "test_dl = dls.test_dl(test_df)\n",
    "learn.validate(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn, dl=test_dl)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def rf(xs, y, n_estimators=40, max_samples=3328,\n",
    "       max_features=0.5, min_samples_leaf=5, **kwargs):\n",
    "    return RandomForestRegressor(n_jobs=-1, n_estimators=n_estimators,\n",
    "        max_samples=max_samples, max_features=max_features,\n",
    "        min_samples_leaf=min_samples_leaf, oob_score=True).fit(xs, y)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs,y = to.train.xs,to.train.y\n",
    "m = rf(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(m, xs)\n",
    "fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fi(fi):\n",
    "    return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)\n",
    "\n",
    "plot_fi(fi[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = fi[fi.imp>0.003].cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep = df[to_keep].copy()\n",
    "df_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df_keep.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = df_keep.select_dtypes(include=[object]).columns.tolist()\n",
    "df = pd.concat([df['clinvar_clnsig'], df_keep], axis=1)\n",
    "splits = RandomSplitter(valid_pct=0.2, seed=42)(range_of(df))\n",
    "df['clinvar_clnsig'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
    "                   cat_names = cat_cols,\n",
    "                   cont_names = num_cols,\n",
    "                   y_names='clinvar_clnsig',\n",
    "                    y_block=CategoryBlock(),\n",
    "                   splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(bs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=accuracy, loss_func=FocalLossFlat(gamma=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(20, lr, wd=0.01)\n",
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('clinvar.22.dbnsfp.vcf', sep='\\t')\n",
    "test_df.replace(to_replace='.', value=np.NaN, inplace=True)\n",
    "test_df.replace(regex='^[.;]+$', value=np.NaN, inplace=True)\n",
    "test_df.apply(pd.to_numeric, errors='ignore')\n",
    "test_df.dropna(axis='rows', how='any', inplace=True, subset=['clinvar_clnsig'])\n",
    "test_df = test_df[df.columns]\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'not_provided'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'protective'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'risk_factor'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'Conflicting_interpretations_of_pathogenicity,_risk_factor'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'Conflicting_interpretations_of_pathogenicity,_other,_risk_factor'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'drug_response'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'association'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'Affects'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'other'].index, inplace=True)\n",
    "test_df.drop(axis='index', labels=test_df[test_df.clinvar_clnsig == 'drug_response,_risk_factor'].index, inplace=True)\n",
    "test_df.replace(to_replace='Conflicting_interpretations_of_pathogenicity', value='Uncertain_significance', inplace=True)\n",
    "test_df.replace(to_replace='Benign/Likely_benign', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Likely_benign,_other', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Likely_benign,_drug_response,_other', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Benign/Likely_benign,_other', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Benign/Likely_benign,_other,_risk_factor', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Benign/Likely_benign,_risk_factor', value='Likely_benign', inplace=True)\n",
    "test_df.replace(to_replace='Pathogenic/Likely_pathogenic', value='Likely_pathogenic', inplace=True)\n",
    "test_dl = dls.test_dl(test_df)\n",
    "learn.validate(dl=test_dl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn, dl=test_dl)\n",
    "interp.plot_confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
